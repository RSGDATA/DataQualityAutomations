{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc0695a",
   "metadata": {},
   "source": [
    "## Function That Parses JSON And Creates A DataFrame To Be Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43132351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the outer level meta data to input as a parameter in the json_normalize() function\n",
    "def outer_flatten_list_with_df(dictionary):\n",
    "    most_outer_list = []\n",
    "    most_outer_df = pd.json_normalize(dictionary).T\n",
    "    most_outer_df['NodePath'] = most_outer_df.index\n",
    "    most_outer_list = []\n",
    "    df_list = []\n",
    "    droplist = []\n",
    "\n",
    "    for i in range(len(most_outer_df)):\n",
    "        ttype = most_outer_df.iloc[i, 0]\n",
    "        if isinstance(ttype, dict) == True:\n",
    "            most_outer_list.append(most_outer_df.index[i])\n",
    "            droplist.append(most_outer_df.index[i])\n",
    "        elif isinstance(ttype, list) == True:\n",
    "            most_outer_list.append(most_outer_df.index[i])\n",
    "            droplist.append(most_outer_df.index[i])\n",
    "        elif isinstance(ttype, list) == True and len(ttype) == 0:\n",
    "            inner_df = most_outer_df['NodePath'].iloc[i]\n",
    "            inner_df['NodePath'].iloc[i] = key + '.' + inner_df\n",
    "        elif isinstance(ttype, list) == True and len(ttype) == 0:\n",
    "            inner_df['NodePath'].iloc[i] = key + '.' + inner_df['NodePath'].iloc[i]\n",
    "            \n",
    "    only_outer_df = most_outer_df.drop(droplist)\n",
    "    df_list.append(only_outer_df)\n",
    "    return [df_list, most_outer_list]\n",
    "\n",
    "# Takes meta data from outer_flatten_list_with_df and parses one level down\n",
    "def inner_flatten_list_with_df1(lst, dictionary):\n",
    "    inner_layers_list = []\n",
    "    df_list = []\n",
    "    droplist = []\n",
    "\n",
    "    if len(lst) == 0:\n",
    "        return 'No values to parse'\n",
    "\n",
    "    for key in lst:\n",
    "        droplist = []\n",
    "        if '.' in key:\n",
    "            keylist = key.split('.')\n",
    "            inner_df = pd.json_normalize(dictionary, record_path=keylist).T\n",
    "            inner_df['NodePath'] = inner_df.index\n",
    "        else:\n",
    "            inner_df = pd.json_normalize(dictionary, record_path=key).T\n",
    "            inner_df['NodePath'] = inner_df.index\n",
    "\n",
    "        for i in range(len(inner_df)):\n",
    "            ttype = inner_df.iloc[i, 0]\n",
    "            if isinstance(ttype, dict) == True:\n",
    "                # mol.append(most_outer_df.index[i])\n",
    "                inner_layers_list.append(key + '.' + inner_df.index[i])\n",
    "                droplist.append(inner_df.index[i])\n",
    "            elif isinstance(ttype, list) == True:\n",
    "                # mol.append(most_outer_df.index[i])\n",
    "                inner_layers_list.append(key + '.' + inner_df.index[i])\n",
    "                droplist.append(inner_df.index[i])\n",
    "            elif isinstance(ttype, list) == True and len(ttype) == 0:\n",
    "                inner_df['NodePath'].iloc[i] = key + '.' + inner_df['NodePath'].iloc[i]\n",
    "            elif isinstance(ttype, list) == True and len(ttype) == 0:\n",
    "                inner_df['NodePath'].iloc[i] = key + '.' + inner_df['NodePath'].iloc[i]\n",
    "            else:\n",
    "                inner_df['NodePath'].iloc[i] = key + '.' + inner_df['NodePath'].iloc[i]\n",
    "\n",
    "        only_outer_df = inner_df.drop(droplist)\n",
    "        df_list.append(only_outer_df)\n",
    "\n",
    "    return [df_list, inner_layers_list]\n",
    "\n",
    "\n",
    "# Takes meta data from outer_flatten_list_with_df and parses one level down\n",
    "def inner_flatten_list_with_df2(lst, dictionary):\n",
    "    inner_layers_list = []\n",
    "    df_list = []\n",
    "    droplist = []\n",
    "\n",
    "    if len(lst) == 0:\n",
    "        return 'No values to parse'\n",
    "\n",
    "    for key in lst:\n",
    "        droplist = []\n",
    "        if '.' in key:\n",
    "            keylist = key.split('.')\n",
    "            inner_df = pd.json_normalize(dictionary, record_path=keylist).T\n",
    "            inner_df['NodePath'] = inner_df.index\n",
    "        else:\n",
    "            inner_df = pd.json_normalize(dictionary, record_path=key).T\n",
    "            inner_df['NodePath'] = inner_df.index\n",
    "\n",
    "        for i in range(len(inner_df)):\n",
    "            ttype = inner_df.iloc[i, 0]\n",
    "            if isinstance(ttype, dict) == True:\n",
    "                # mol.append(most_outer_df.index[i])\n",
    "                inner_layers_list.append(key + '.' + inner_df.index[i])\n",
    "                droplist.append(inner_df.index[i])\n",
    "            elif isinstance(ttype, list) == True:\n",
    "                # mol.append(most_outer_df.index[i])\n",
    "                inner_layers_list.append(key + '.' + inner_df.index[i])\n",
    "                droplist.append(inner_df.index[i])\n",
    "            elif isinstance(ttype, list) == True and len(ttype) == 0:\n",
    "                inner_df['NodePath'].iloc[i] = key + '.' + inner_df['NodePath'].iloc[i]\n",
    "            elif isinstance(ttype, list) == True and len(ttype) == 0:\n",
    "                inner_df['NodePath'].iloc[i] = key + '.' + inner_df['NodePath'].iloc[i]\n",
    "            else:\n",
    "                inner_df['NodePath'].iloc[i] = key + '.' + inner_df['NodePath'].iloc[i]\n",
    "\n",
    "        only_outer_df = inner_df.drop(droplist)\n",
    "        df_list.append(only_outer_df)\n",
    "\n",
    "    return [df_list, inner_layers_list]\n",
    "\n",
    "\n",
    "# Uses the three functions and creates a pattern that will parse down to the lowest level in a given JSON.\n",
    "def json_dataset(dictionary):\n",
    "    all_meta_data = []\n",
    "    nested_list_of_dataframes = []\n",
    "\n",
    "    outer_list = outer_flatten_list_with_df(dictionary)[1]\n",
    "    outer_df = outer_flatten_list_with_df(dictionary)[0]\n",
    "\n",
    "    all_meta_data.append(outer_list)\n",
    "    nested_list_of_dataframes.append(outer_df)\n",
    "\n",
    "    inner_flatten_list = inner_flatten_list_with_df(outer_list, dictionary)[1]\n",
    "    inner_flatten_df1 = inner_flatten_list_with_df(outer_list, dictionary)[0]\n",
    "\n",
    "    all_meta_data.append(inner_flatten_list)\n",
    "    nested_list_of_dataframes.append(inner_flatten_df1)\n",
    "\n",
    "    while len(inner_flatten_list) > 0:\n",
    "        inner_flatten_list = inner_flatten_list_with_df2(inner_flatten_list, dictionary)[1]\n",
    "        inner_flatten_df2 = inner_flatten_list_with_df2(inner_flatten_list, dictionary)[0]\n",
    "        all_meta_data.append(inner_flatten_list)\n",
    "        nested_list_of_dataframes.append(inner_flatten_df2)\n",
    "\n",
    "    # if len(inner_flatten_list) > 0:\n",
    "    #     inner_flatten_list = inner_flatten1(inner_flatten_list, dictionary)\n",
    "    #     all_meta_data.append(inner_flatten_list)\n",
    "\n",
    "    json_dataframe_list = []\n",
    "    for dflist in nested_list_of_dataframes:\n",
    "        for df in dflist:\n",
    "            json_dataframe_list.append(df)\n",
    "\n",
    "    deal_concatdf = pd.concat(json_dataframe_list[:-1]).sort_values(by='NodePath')\n",
    "    sorted_json_concatdf = deal_concatdf.rename(columns={0: \"Values\"})\n",
    "    json_concatdf = sorted_json_concatdf[['NodePath', 'Values', 1, 2]]\n",
    "\n",
    "    return json_concatdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2daa8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2784441965.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 25\u001b[0;36m\u001b[0m\n\u001b[0;31m    ],\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "json = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"MainId\": 1111,\n",
    "            \"firstName\": \"Sherlock\",\n",
    "            \"lastName\": \"Homes\",\n",
    "            \"categories\": [\n",
    "                {\n",
    "                    \"CategoryID\": 1,\n",
    "                    \"CategoryName\": \"Example\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"MainId\": 122,\n",
    "            \"firstName\": \"James\",\n",
    "            \"lastName\": \"Watson\",\n",
    "            \"categories\": [\n",
    "                {\n",
    "                    \"CategoryID\": 2,\n",
    "                    \"CategoryName\": \"Example2\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59c981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
